Using parameters:
  DATASET: aime24
  TEMP: 1.0
  TOP_P: 0.99
  TOP_K: -1
  RP: 1.0
  K: 2
  MODEL: ckpt/autodeco-qwen3-4b-thinking/
  TP_SIZE: 1

Generating 8 random seeds and running llm_eval with TP=1...
Generated seed 1: 15399
Generated seed 2: 14056
Generated seed 3: 7484
Generated seed 4: 29122
Generated seed 5: 24184
Generated seed 6: 14722
Generated seed 7: 1905
Generated seed 8: 222

All seeds: 15399 14056 7484 29122 24184 14722 1905 222

Starting tasks in batches of 4 (each uses 1 GPU)...
Starting task 1 with seed 15399 on GPU 0 (TP=1)
Starting task 2 with seed 14056 on GPU 1 (TP=1)
Starting task 3 with seed 7484 on GPU 2 (TP=1)
Starting task 4 with seed 29122 on GPU 3 (TP=1)
INFO 02-14 03:57:34 [__init__.py:216] Automatically detected platform cuda.
INFO 02-14 03:57:34 [__init__.py:216] Automatically detected platform cuda.
INFO 02-14 03:57:34 [__init__.py:216] Automatically detected platform cuda.
INFO 02-14 03:57:34 [__init__.py:216] Automatically detected platform cuda.
AutoDeco model registered with transformers (AutoConfig, AutoModel, AutoModelForCausalLM)
AutoDeco model registered with transformers (AutoConfig, AutoModel, AutoModelForCausalLM)
AutoDeco model registered with transformers (AutoConfig, AutoModel, AutoModelForCausalLM)
AutoDeco model registered with transformers (AutoConfig, AutoModel, AutoModelForCausalLM)
INFO 02-14 03:57:39 [utils.py:328] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'model': 'ckpt/autodeco-qwen3-4b-thinking/'}
INFO 02-14 03:57:39 [utils.py:328] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'model': 'ckpt/autodeco-qwen3-4b-thinking/'}
INFO 02-14 03:57:39 [utils.py:328] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'model': 'ckpt/autodeco-qwen3-4b-thinking/'}
INFO 02-14 03:57:39 [utils.py:328] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'model': 'ckpt/autodeco-qwen3-4b-thinking/'}
INFO 02-14 03:57:50 [__init__.py:742] Resolved architecture: AutoDecoModelForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 02-14 03:57:50 [__init__.py:1815] Using max model len 32768
INFO 02-14 03:57:51 [__init__.py:742] Resolved architecture: AutoDecoModelForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 02-14 03:57:51 [__init__.py:1815] Using max model len 32768
INFO 02-14 03:57:51 [__init__.py:742] Resolved architecture: AutoDecoModelForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 02-14 03:57:51 [__init__.py:1815] Using max model len 32768
INFO 02-14 03:57:51 [__init__.py:742] Resolved architecture: AutoDecoModelForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 02-14 03:57:51 [__init__.py:1815] Using max model len 32768
INFO 02-14 03:57:52 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=16384.
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:52 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:52 [core.py:76] Initializing a V1 LLM engine (v0.1.dev9404+gaad21055a) with config: model='ckpt/autodeco-qwen3-4b-thinking/', speculative_config=None, tokenizer='ckpt/autodeco-qwen3-4b-thinking/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=ckpt/autodeco-qwen3-4b-thinking/, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
INFO 02-14 03:57:52 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-14 03:57:53 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-14 03:57:53 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=16384.
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:53 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:53 [core.py:76] Initializing a V1 LLM engine (v0.1.dev9404+gaad21055a) with config: model='ckpt/autodeco-qwen3-4b-thinking/', speculative_config=None, tokenizer='ckpt/autodeco-qwen3-4b-thinking/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=ckpt/autodeco-qwen3-4b-thinking/, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:54 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:54 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:54 [core.py:76] Initializing a V1 LLM engine (v0.1.dev9404+gaad21055a) with config: model='ckpt/autodeco-qwen3-4b-thinking/', speculative_config=None, tokenizer='ckpt/autodeco-qwen3-4b-thinking/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=ckpt/autodeco-qwen3-4b-thinking/, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:54 [core.py:76] Initializing a V1 LLM engine (v0.1.dev9404+gaad21055a) with config: model='ckpt/autodeco-qwen3-4b-thinking/', speculative_config=None, tokenizer='ckpt/autodeco-qwen3-4b-thinking/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=ckpt/autodeco-qwen3-4b-thinking/, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[W214 03:57:55.839336752 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:55 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=6953)[0;0m WARNING 02-14 03:57:55 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:55 [gpu_model_runner.py:2430] Starting to load model ckpt/autodeco-qwen3-4b-thinking/...
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:55 [gpu_model_runner.py:2462] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:55 [autodeco.py:149] ================================================================================
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:55 [autodeco.py:150] Initializing AutoDeco model for vLLM:
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:55 [autodeco.py:151]   - base_model_type: qwen3
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:55 [autodeco.py:152]   - use_enhanced_features: True
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:55 [autodeco.py:153]   - hidden_size: 2560
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:55 [autodeco.py:154] ================================================================================
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:55 [autodeco.py:165]   - Loading base model class: Qwen3ForCausalLM
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:56 [cuda.py:362] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:56 [autodeco.py:201] âœ“ AutoDeco model initialized successfully
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:56 [autodeco.py:202] ================================================================================
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:56 [autodeco.py:348] Loading AutoDeco weights from merged checkpoint...
[1;36m(EngineCore_DP0 pid=6953)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[W214 03:57:56.051921111 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:56 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=6968)[0;0m WARNING 02-14 03:57:56 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:56 [gpu_model_runner.py:2430] Starting to load model ckpt/autodeco-qwen3-4b-thinking/...
[W214 03:57:56.459034685 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:56 [gpu_model_runner.py:2462] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:56 [autodeco.py:149] ================================================================================
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:56 [autodeco.py:150] Initializing AutoDeco model for vLLM:
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:56 [autodeco.py:151]   - base_model_type: qwen3
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:56 [autodeco.py:152]   - use_enhanced_features: True
[Gloo] Rank 0 is connected to 0 peer ranks. [1;36m(EngineCore_DP0 pid=6968)[0;0m Expected number of connected peer ranks is : 0INFO 02-14 03:57:56 [autodeco.py:153]   - hidden_size: 2560

[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:56 [autodeco.py:154] ================================================================================
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:56 [autodeco.py:165]   - Loading base model class: Qwen3ForCausalLM
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:56 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=6978)[0;0m WARNING 02-14 03:57:56 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[W214 03:57:57.512608758 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=6977)[0;0m WARNING 02-14 03:57:57 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [gpu_model_runner.py:2430] Starting to load model ckpt/autodeco-qwen3-4b-thinking/...
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:57 [cuda.py:362] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [gpu_model_runner.py:2430] Starting to load model ckpt/autodeco-qwen3-4b-thinking/...
[1;36m(EngineCore_DP0 pid=6953)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:00<00:01,  1.49it/s]
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:57 [autodeco.py:201] âœ“ AutoDeco model initialized successfully
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:57 [autodeco.py:202] ================================================================================
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:57 [autodeco.py:348] Loading AutoDeco weights from merged checkpoint...
[1;36m(EngineCore_DP0 pid=6968)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [gpu_model_runner.py:2462] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [autodeco.py:149] ================================================================================
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [autodeco.py:150] Initializing AutoDeco model for vLLM:
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [autodeco.py:151]   - base_model_type: qwen3
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [autodeco.py:152]   - use_enhanced_features: True
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [autodeco.py:153]   - hidden_size: 2560
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [autodeco.py:154] ================================================================================
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [autodeco.py:165]   - Loading base model class: Qwen3ForCausalLM
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [gpu_model_runner.py:2462] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [autodeco.py:149] ================================================================================
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [autodeco.py:150] Initializing AutoDeco model for vLLM:
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [autodeco.py:151]   - base_model_type: qwen3
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [autodeco.py:152]   - use_enhanced_features: True
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [autodeco.py:153]   - hidden_size: 2560
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [autodeco.py:154] ================================================================================
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [autodeco.py:165]   - Loading base model class: Qwen3ForCausalLM
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [cuda.py:362] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [cuda.py:362] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [autodeco.py:201] âœ“ AutoDeco model initialized successfully
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [autodeco.py:202] ================================================================================
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:57 [autodeco.py:348] Loading AutoDeco weights from merged checkpoint...
[1;36m(EngineCore_DP0 pid=6978)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [autodeco.py:201] âœ“ AutoDeco model initialized successfully
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [autodeco.py:202] ================================================================================
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:57 [autodeco.py:348] Loading AutoDeco weights from merged checkpoint...
[1;36m(EngineCore_DP0 pid=6977)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=6953)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:01<00:00,  1.39it/s]
[1;36m(EngineCore_DP0 pid=6968)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:00<00:01,  1.50it/s]
[1;36m(EngineCore_DP0 pid=6953)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  2.24it/s]
[1;36m(EngineCore_DP0 pid=6953)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  1.94it/s]
[1;36m(EngineCore_DP0 pid=6953)[0;0m 
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:58 [autodeco.py:359] âœ“ Successfully loaded 298 parameters
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:58 [autodeco.py:366]   - Base model (llm.*): 290 parameters
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:58 [autodeco.py:367]   - Temperature head (temp_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:58 [autodeco.py:368]   - Top-p head (top_p_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:58 [default_loader.py:268] Loading weights took 1.55 seconds
[1;36m(EngineCore_DP0 pid=6978)[0;0m [1;36m(EngineCore_DP0 pid=6977)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:00<00:01,  1.31it/s]
Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:00<00:01,  1.33it/s]
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:57:58 [gpu_model_runner.py:2484] Model loading took 7.6094 GiB and 2.219592 seconds
[1;36m(EngineCore_DP0 pid=6968)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:01<00:00,  1.40it/s]
[1;36m(EngineCore_DP0 pid=6968)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  2.27it/s]
[1;36m(EngineCore_DP0 pid=6968)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  1.96it/s]
[1;36m(EngineCore_DP0 pid=6968)[0;0m 
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:58 [autodeco.py:359] âœ“ Successfully loaded 298 parameters
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:58 [autodeco.py:366]   - Base model (llm.*): 290 parameters
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:58 [autodeco.py:367]   - Temperature head (temp_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:58 [autodeco.py:368]   - Top-p head (top_p_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:58 [default_loader.py:268] Loading weights took 1.54 seconds
[1;36m(EngineCore_DP0 pid=6977)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=6977)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  1.90it/s]
[1;36m(EngineCore_DP0 pid=6977)[0;0m 
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:59 [autodeco.py:359] âœ“ Successfully loaded 298 parameters
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:59 [autodeco.py:366]   - Base model (llm.*): 290 parameters
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:59 [autodeco.py:367]   - Temperature head (temp_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:59 [autodeco.py:368]   - Top-p head (top_p_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:59 [default_loader.py:268] Loading weights took 1.59 seconds
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:57:59 [gpu_model_runner.py:2484] Model loading took 7.6094 GiB and 1.860499 seconds
[1;36m(EngineCore_DP0 pid=6978)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:01<00:00,  1.18it/s]
[1;36m(EngineCore_DP0 pid=6978)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  1.94it/s]
[1;36m(EngineCore_DP0 pid=6978)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  1.67it/s]
[1;36m(EngineCore_DP0 pid=6978)[0;0m 
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:59 [autodeco.py:359] âœ“ Successfully loaded 298 parameters
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:59 [autodeco.py:366]   - Base model (llm.*): 290 parameters
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:59 [autodeco.py:367]   - Temperature head (temp_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:59 [autodeco.py:368]   - Top-p head (top_p_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:57:59 [default_loader.py:268] Loading weights took 1.80 seconds
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:57:59 [gpu_model_runner.py:2484] Model loading took 7.6094 GiB and 1.967207 seconds
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:58:00 [gpu_model_runner.py:2484] Model loading took 7.6094 GiB and 2.205072 seconds
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:58:09 [backends.py:537] vLLM's torch.compile cache is disabled.
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:58:09 [backends.py:550] Dynamo bytecode transform time: 10.87 s
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:58:10 [backends.py:537] vLLM's torch.compile cache is disabled.
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:58:10 [backends.py:550] Dynamo bytecode transform time: 10.98 s
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:58:11 [backends.py:537] vLLM's torch.compile cache is disabled.
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:58:11 [backends.py:550] Dynamo bytecode transform time: 11.16 s
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:58:11 [backends.py:537] vLLM's torch.compile cache is disabled.
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:58:11 [backends.py:550] Dynamo bytecode transform time: 11.44 s
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:58:29 [backends.py:215] Compiling a graph for dynamic shape takes 17.79 s
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:58:30 [monitor.py:34] torch.compile takes 28.66 s in total
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:58:30 [backends.py:215] Compiling a graph for dynamic shape takes 16.69 s
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:58:30 [backends.py:215] Compiling a graph for dynamic shape takes 17.86 s
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:58:31 [monitor.py:34] torch.compile takes 27.85 s in total
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:58:31 [backends.py:215] Compiling a graph for dynamic shape takes 17.16 s
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:58:31 [gpu_worker.py:298] Available KV cache memory: 57.96 GiB
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:58:31 [monitor.py:34] torch.compile takes 28.83 s in total
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:58:32 [kv_cache_utils.py:864] GPU KV cache size: 422,016 tokens
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:58:32 [kv_cache_utils.py:868] Maximum concurrency for 32,768 tokens per request: 12.88x
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:58:32 [monitor.py:34] torch.compile takes 28.60 s in total
[1;36m(EngineCore_DP0 pid=6953)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|                                                     | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–ˆâ–Ž                                           | 2/67 [00:00<00:03, 16.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–ˆâ–ˆâ–‹                                          | 4/67 [00:00<00:03, 16.79it/s][1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:58:32 [gpu_worker.py:298] Available KV cache memory: 57.96 GiB
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                                        | 7/67 [00:00<00:03, 18.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 9/67 [00:00<00:03, 18.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 11/67 [00:00<00:03, 18.59it/s][1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:58:33 [kv_cache_utils.py:864] GPU KV cache size: 422,016 tokens
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:58:33 [kv_cache_utils.py:868] Maximum concurrency for 32,768 tokens per request: 12.88x
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                   | 13/67 [00:00<00:02, 18.82it/s][1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:58:33 [gpu_worker.py:298] Available KV cache memory: 57.96 GiB
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                  | 15/67 [00:00<00:02, 18.61it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 17/67 [00:00<00:02, 18.35it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                               | 19/67 [00:01<00:02, 17.20it/s][1;36m(EngineCore_DP0 pid=6978)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|                                                     | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 21/67 [00:01<00:02, 17.55it/s][1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:58:33 [kv_cache_utils.py:864] GPU KV cache size: 422,016 tokens
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:58:33 [kv_cache_utils.py:868] Maximum concurrency for 32,768 tokens per request: 12.88x
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–ˆâ–Ž                                           | 2/67 [00:00<00:03, 18.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 23/67 [00:01<00:02, 17.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–ˆâ–ˆâ–‹                                          | 4/67 [00:00<00:03, 19.21it/s][1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:58:33 [gpu_worker.py:298] Available KV cache memory: 57.96 GiB
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                           | 25/67 [00:01<00:02, 17.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–ˆâ–ˆâ–ˆâ–ˆ                                         | 6/67 [00:00<00:03, 19.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 27/67 [00:01<00:02, 15.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                       | 8/67 [00:00<00:03, 17.15it/s][1;36m(EngineCore_DP0 pid=6968)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|                                                     | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 29/67 [00:01<00:02, 15.31it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                     | 10/67 [00:00<00:03, 16.39it/s][1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:58:34 [kv_cache_utils.py:864] GPU KV cache size: 422,016 tokens
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:58:34 [kv_cache_utils.py:868] Maximum concurrency for 32,768 tokens per request: 12.88x
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–ˆâ–Ž                                           | 2/67 [00:00<00:04, 15.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 31/67 [00:01<00:02, 15.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                    | 12/67 [00:00<00:03, 17.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                  | 14/67 [00:00<00:02, 17.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–ˆâ–ˆâ–ˆâ–Ž                                         | 5/67 [00:00<00:03, 18.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 33/67 [00:01<00:02, 14.84it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                 | 16/67 [00:00<00:02, 18.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                                        | 7/67 [00:00<00:03, 19.01it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 35/67 [00:02<00:02, 15.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                | 18/67 [00:00<00:02, 18.46it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 9/67 [00:00<00:03, 18.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 37/67 [00:02<00:01, 15.29it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 20/67 [00:01<00:02, 17.50it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 11/67 [00:00<00:03, 16.77it/s][1;36m(EngineCore_DP0 pid=6977)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|                                                     | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 39/67 [00:02<00:01, 15.18it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                             | 22/67 [00:01<00:02, 17.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                   | 13/67 [00:00<00:03, 17.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–ˆâ–Ž                                           | 2/67 [00:00<00:03, 17.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                            | 24/67 [00:01<00:02, 18.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 41/67 [00:02<00:01, 15.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                  | 15/67 [00:00<00:02, 17.49it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–ˆâ–ˆâ–ˆâ–Ž                                         | 5/67 [00:00<00:03, 19.40it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 26/67 [00:01<00:02, 17.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 43/67 [00:02<00:01, 15.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 17/67 [00:00<00:02, 17.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                                        | 7/67 [00:00<00:03, 19.18it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 28/67 [00:01<00:02, 17.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 45/67 [00:02<00:01, 15.95it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                               | 19/67 [00:01<00:02, 17.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 9/67 [00:00<00:03, 18.53it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 30/67 [00:01<00:02, 18.15it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 47/67 [00:02<00:01, 16.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 21/67 [00:01<00:02, 18.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 11/67 [00:00<00:03, 18.65it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 32/67 [00:01<00:01, 18.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 23/67 [00:01<00:02, 18.20it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 49/67 [00:02<00:01, 16.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                   | 13/67 [00:00<00:03, 17.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                           | 25/67 [00:01<00:02, 17.30it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 34/67 [00:01<00:02, 15.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 51/67 [00:03<00:01, 14.69it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                  | 15/67 [00:00<00:03, 16.20it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 36/67 [00:02<00:01, 15.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 27/67 [00:01<00:02, 16.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 53/67 [00:03<00:00, 14.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 17/67 [00:00<00:03, 16.47it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 38/67 [00:02<00:01, 15.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 29/67 [00:01<00:02, 15.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                               | 19/67 [00:01<00:02, 16.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 55/67 [00:03<00:00, 14.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 40/67 [00:02<00:01, 15.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 31/67 [00:01<00:02, 16.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 21/67 [00:01<00:02, 16.03it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 57/67 [00:03<00:00, 14.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 42/67 [00:02<00:01, 15.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 33/67 [00:01<00:02, 13.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 23/67 [00:01<00:02, 15.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/67 [00:03<00:00, 14.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 44/67 [00:02<00:01, 14.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 35/67 [00:02<00:02, 14.69it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                           | 25/67 [00:01<00:02, 16.30it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/67 [00:03<00:00, 14.32it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 46/67 [00:02<00:01, 15.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 37/67 [00:02<00:01, 15.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 27/67 [00:01<00:02, 16.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 63/67 [00:03<00:00, 14.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 48/67 [00:02<00:01, 15.40it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 29/67 [00:01<00:02, 17.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 39/67 [00:02<00:01, 15.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65/67 [00:04<00:00, 15.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 50/67 [00:02<00:01, 15.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 31/67 [00:01<00:02, 17.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 41/67 [00:02<00:01, 16.02it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 15.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 15.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 52/67 [00:03<00:01, 14.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 43/67 [00:02<00:01, 15.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 33/67 [00:01<00:02, 14.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 54/67 [00:03<00:00, 14.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 45/67 [00:02<00:01, 15.17it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 35/67 [00:02<00:02, 15.43it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 56/67 [00:03<00:00, 15.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 37/67 [00:02<00:01, 15.98it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 47/67 [00:02<00:01, 15.40it/s][1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:58:37 [gpu_model_runner.py:3215] Graph capturing finished in 5 secs, took 0.54 GiB
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:58:37 [gpu_worker.py:391] Free memory on device (78.57/79.18 GiB) on startup. Desired GPU memory utilization is (0.9, 71.26 GiB). Actual usage is 7.61 GiB for weight, 5.63 GiB for peak activation, 0.07 GiB for non-torch memory, and 0.54 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=61493640294` to fit into requested memory, or `--kv-cache-memory=69346530816` to fully utilize gpu memory. Current kv cache memory in use is 62229740646 bytes.
[1;36m(EngineCore_DP0 pid=6953)[0;0m INFO 02-14 03:58:37 [core.py:218] init engine (profile, create kv cache, warmup model) took 38.49 seconds
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 58/67 [00:03<00:00, 15.71it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 49/67 [00:03<00:01, 15.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 39/67 [00:02<00:01, 15.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 60/67 [00:03<00:00, 15.95it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 41/67 [00:02<00:01, 16.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 51/67 [00:03<00:01, 15.40it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 62/67 [00:03<00:00, 16.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 43/67 [00:02<00:01, 16.35it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 53/67 [00:03<00:00, 15.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/67 [00:03<00:00, 15.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 45/67 [00:02<00:01, 15.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 55/67 [00:03<00:00, 13.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 66/67 [00:04<00:00, 14.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 47/67 [00:02<00:01, 14.12it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 16.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 57/67 [00:03<00:00, 12.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 49/67 [00:03<00:01, 13.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/67 [00:03<00:00, 12.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 51/67 [00:03<00:01, 13.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/67 [00:03<00:00, 12.76it/s][1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:58:38 [gpu_model_runner.py:3215] Graph capturing finished in 5 secs, took 0.54 GiB
[1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:58:38 [gpu_worker.py:391] Free memory on device (78.57/79.18 GiB) on startup. Desired GPU memory utilization is (0.9, 71.26 GiB). Actual usage is 7.61 GiB for weight, 5.63 GiB for peak activation, 0.07 GiB for non-torch memory, and 0.54 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=61493640294` to fit into requested memory, or `--kv-cache-memory=69346530816` to fully utilize gpu memory. Current kv cache memory in use is 62229740646 bytes.
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 53/67 [00:03<00:01, 12.55it/s][1;36m(EngineCore_DP0 pid=6978)[0;0m INFO 02-14 03:58:38 [core.py:218] init engine (profile, create kv cache, warmup model) took 38.17 seconds
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 63/67 [00:04<00:00, 12.78it/s]INFO 02-14 03:58:38 [llm.py:295] Supported_tasks: ['generate']
INFO 02-14 03:58:38 [__init__.py:36] No IOProcessor plugins requested by the model
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 55/67 [00:03<00:00, 12.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65/67 [00:04<00:00, 13.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 57/67 [00:03<00:00, 13.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 14.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 15.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/67 [00:03<00:00, 13.96it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/67 [00:03<00:00, 13.52it/s]Adding requests:   0%|                                                                                             | 0/30 [00:00<?, ?it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 853.11it/s]
Processed prompts:   0%|                                       | 0/60 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 63/67 [00:04<00:00, 13.86it/s][1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:58:38 [gpu_model_runner.py:3215] Graph capturing finished in 5 secs, took 0.54 GiB
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:58:38 [gpu_worker.py:391] Free memory on device (78.57/79.18 GiB) on startup. Desired GPU memory utilization is (0.9, 71.26 GiB). Actual usage is 7.61 GiB for weight, 5.63 GiB for peak activation, 0.07 GiB for non-torch memory, and 0.54 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=61493640294` to fit into requested memory, or `--kv-cache-memory=69346530816` to fully utilize gpu memory. Current kv cache memory in use is 62229740646 bytes.
[1;36m(EngineCore_DP0 pid=6968)[0;0m INFO 02-14 03:58:39 [core.py:218] init engine (profile, create kv cache, warmup model) took 39.63 seconds
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65/67 [00:04<00:00, 14.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 14.25it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 15.32it/s]
INFO 02-14 03:58:39 [llm.py:295] Supported_tasks: ['generate']
INFO 02-14 03:58:39 [__init__.py:36] No IOProcessor plugins requested by the model
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:58:39 [gpu_model_runner.py:3215] Graph capturing finished in 5 secs, took 0.54 GiB
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:58:39 [gpu_worker.py:391] Free memory on device (78.57/79.18 GiB) on startup. Desired GPU memory utilization is (0.9, 71.26 GiB). Actual usage is 7.61 GiB for weight, 5.63 GiB for peak activation, 0.07 GiB for non-torch memory, and 0.54 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=61493640294` to fit into requested memory, or `--kv-cache-memory=69346530816` to fully utilize gpu memory. Current kv cache memory in use is 62229740646 bytes.
[1;36m(EngineCore_DP0 pid=6977)[0;0m INFO 02-14 03:58:39 [core.py:218] init engine (profile, create kv cache, warmup model) took 39.72 seconds
Adding requests:   0%|                                                                                             | 0/30 [00:00<?, ?it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 849.77it/s]
Processed prompts:   0%|                                       | 0/60 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]INFO 02-14 03:58:40 [llm.py:295] Supported_tasks: ['generate']
INFO 02-14 03:58:40 [__init__.py:36] No IOProcessor plugins requested by the model
Adding requests:   0%|                                                                                             | 0/30 [00:00<?, ?it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 842.80it/s]
Processed prompts:   0%|                                       | 0/60 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]INFO 02-14 03:58:40 [llm.py:295] Supported_tasks: ['generate']
INFO 02-14 03:58:40 [__init__.py:36] No IOProcessor plugins requested by the model
Adding requests:   0%|                                                                                             | 0/30 [00:00<?, ?it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 897.80it/s]
Processed prompts:   0%|                                       | 0/60 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|â–‰                           | 2/60 [02:15<1:05:37, 67.88s/it, est. speed input: 2.15 toks/s, output: 95.53 toks/s]Processed prompts:   3%|â–‰                           | 2/60 [02:19<1:07:37, 69.95s/it, est. speed input: 2.09 toks/s, output: 94.39 toks/s]Processed prompts:   3%|â–‰                           | 2/60 [02:24<1:10:03, 72.47s/it, est. speed input: 2.01 toks/s, output: 91.92 toks/s]Processed prompts:   7%|â–ˆâ–‰                           | 4/60 [02:28<28:50, 30.91s/it, est. speed input: 2.92 toks/s, output: 183.65 toks/s]Processed prompts:   3%|â–‰                           | 2/60 [02:33<1:14:12, 76.77s/it, est. speed input: 2.01 toks/s, output: 96.02 toks/s]Processed prompts:   7%|â–ˆâ–‰                           | 4/60 [02:36<30:25, 32.60s/it, est. speed input: 3.82 toks/s, output: 185.86 toks/s]Processed prompts:   7%|â–ˆâ–‰                           | 4/60 [02:46<34:10, 36.61s/it, est. speed input: 3.74 toks/s, output: 167.80 toks/s]Processed prompts:   7%|â–ˆâ–‰                           | 4/60 [02:52<36:11, 38.79s/it, est. speed input: 3.48 toks/s, output: 161.08 toks/s]Processed prompts:  10%|â–ˆâ–ˆâ–‰                          | 6/60 [02:59<21:30, 23.89s/it, est. speed input: 4.25 toks/s, output: 238.94 toks/s]Processed prompts:  10%|â–ˆâ–ˆâ–‰                          | 6/60 [03:04<21:36, 24.02s/it, est. speed input: 5.04 toks/s, output: 245.69 toks/s]Processed prompts:  10%|â–ˆâ–ˆâ–‰                          | 6/60 [03:04<21:30, 23.90s/it, est. speed input: 4.15 toks/s, output: 232.28 toks/s]Processed prompts:  10%|â–ˆâ–ˆâ–‰                          | 6/60 [03:18<24:19, 27.02s/it, est. speed input: 4.68 toks/s, output: 221.99 toks/s]Processed prompts:  13%|â–ˆâ–ˆâ–ˆâ–Š                         | 8/60 [03:21<15:28, 17.86s/it, est. speed input: 5.33 toks/s, output: 300.01 toks/s]Processed prompts:  13%|â–ˆâ–ˆâ–ˆâ–Š                         | 8/60 [03:24<16:44, 19.33s/it, est. speed input: 5.25 toks/s, output: 290.80 toks/s]Processed prompts:  13%|â–ˆâ–ˆâ–ˆâ–Š                         | 8/60 [03:27<15:39, 18.06s/it, est. speed input: 5.77 toks/s, output: 298.02 toks/s]Processed prompts:  13%|â–ˆâ–ˆâ–ˆâ–Š                         | 8/60 [03:32<17:22, 20.05s/it, est. speed input: 5.63 toks/s, output: 300.30 toks/s]Processed prompts:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 10/60 [03:46<12:51, 15.43s/it, est. speed input: 5.90 toks/s, output: 364.44 toks/s]Processed prompts:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 10/60 [03:54<14:51, 17.83s/it, est. speed input: 5.16 toks/s, output: 332.51 toks/s]Processed prompts:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 10/60 [03:58<15:10, 18.21s/it, est. speed input: 5.07 toks/s, output: 330.56 toks/s]Processed prompts:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 10/60 [04:03<15:00, 18.02s/it, est. speed input: 5.54 toks/s, output: 337.45 toks/s]Processed prompts:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 12/60 [04:07<10:03, 12.58s/it, est. speed input: 6.00 toks/s, output: 411.62 toks/s]Processed prompts:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 12/60 [04:10<11:21, 14.20s/it, est. speed input: 6.62 toks/s, output: 414.05 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 14/60 [04:12<07:32,  9.84s/it, est. speed input: 7.12 toks/s, output: 491.63 toks/s]Processed prompts:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 12/60 [04:17<12:06, 15.14s/it, est. speed input: 5.95 toks/s, output: 391.07 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 14/60 [04:21<08:22, 10.92s/it, est. speed input: 6.42 toks/s, output: 466.22 toks/s]Processed prompts:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 12/60 [04:26<13:41, 17.11s/it, est. speed input: 5.55 toks/s, output: 367.62 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 14/60 [04:58<12:54, 16.83s/it, est. speed input: 5.45 toks/s, output: 409.05 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 14/60 [05:19<15:33, 20.29s/it, est. speed input: 5.09 toks/s, output: 381.10 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 16/60 [05:32<11:42, 15.97s/it, est. speed input: 5.92 toks/s, output: 440.87 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 16/60 [05:39<15:03, 20.52s/it, est. speed input: 6.00 toks/s, output: 441.21 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 16/60 [05:42<13:35, 18.52s/it, est. speed input: 5.75 toks/s, output: 433.71 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 16/60 [05:47<15:31, 21.18s/it, est. speed input: 5.59 toks/s, output: 419.64 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 18/60 [06:10<11:46, 16.82s/it, est. speed input: 5.97 toks/s, output: 467.95 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 18/60 [06:10<11:58, 17.10s/it, est. speed input: 5.96 toks/s, output: 477.94 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 20/60 [06:13<08:08, 12.20s/it, est. speed input: 6.32 toks/s, output: 547.57 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 22/60 [06:18<05:50,  9.23s/it, est. speed input: 7.08 toks/s, output: 598.28 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 18/60 [06:30<15:28, 22.11s/it, est. speed input: 6.10 toks/s, output: 457.66 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 20/60 [06:35<10:17, 15.43s/it, est. speed input: 6.01 toks/s, output: 516.55 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 20/60 [06:44<11:37, 17.45s/it, est. speed input: 6.26 toks/s, output: 510.43 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 18/60 [06:43<16:18, 23.31s/it, est. speed input: 5.67 toks/s, output: 427.27 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 20/60 [07:01<12:33, 18.83s/it, est. speed input: 6.00 toks/s, output: 484.93 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 22/60 [07:10<10:10, 16.07s/it, est. speed input: 6.26 toks/s, output: 537.13 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 22/60 [07:11<09:13, 14.56s/it, est. speed input: 6.35 toks/s, output: 543.53 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 24/60 [07:21<09:39, 16.11s/it, est. speed input: 6.53 toks/s, output: 588.59 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 26/60 [07:27<06:48, 12.03s/it, est. speed input: 6.82 toks/s, output: 626.82 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 24/60 [07:29<08:26, 14.08s/it, est. speed input: 6.43 toks/s, output: 581.48 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 22/60 [07:40<13:07, 20.72s/it, est. speed input: 5.85 toks/s, output: 514.61 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 28/60 [07:39<05:27, 10.22s/it, est. speed input: 7.07 toks/s, output: 679.50 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 26/60 [07:50<07:22, 13.00s/it, est. speed input: 6.56 toks/s, output: 627.45 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 24/60 [07:56<10:10, 16.96s/it, est. speed input: 6.17 toks/s, output: 560.69 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 30/60 [08:03<05:21, 10.72s/it, est. speed input: 7.55 toks/s, output: 721.32 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 26/60 [08:18<08:37, 15.24s/it, est. speed input: 6.21 toks/s, output: 605.12 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 24/60 [08:23<12:31, 20.89s/it, est. speed input: 5.74 toks/s, output: 537.98 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 28/60 [08:25<07:39, 14.37s/it, est. speed input: 6.43 toks/s, output: 625.25 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 28/60 [08:35<06:59, 13.12s/it, est. speed input: 6.51 toks/s, output: 657.83 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 30/60 [08:35<04:37,  9.25s/it, est. speed input: 6.88 toks/s, output: 713.06 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 32/60 [08:37<03:07,  6.71s/it, est. speed input: 7.70 toks/s, output: 785.28 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 26/60 [08:43<09:57, 17.58s/it, est. speed input: 5.85 toks/s, output: 587.45 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 28/60 [08:54<07:29, 14.05s/it, est. speed input: 6.16 toks/s, output: 644.38 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 34/60 [08:58<03:24,  7.87s/it, est. speed input: 7.70 toks/s, output: 797.04 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 36/60 [09:14<03:09,  7.91s/it, est. speed input: 8.20 toks/s, output: 845.95 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 32/60 [09:34<09:56, 21.30s/it, est. speed input: 6.62 toks/s, output: 671.68 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 30/60 [09:55<09:29, 18.98s/it, est. speed input: 5.81 toks/s, output: 611.53 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 30/60 [09:54<11:45, 23.53s/it, est. speed input: 5.75 toks/s, output: 599.09 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 32/60 [09:58<06:25, 13.75s/it, est. speed input: 6.10 toks/s, output: 664.22 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 34/60 [10:05<04:36, 10.63s/it, est. speed input: 6.75 toks/s, output: 727.46 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 34/60 [10:17<09:12, 21.25s/it, est. speed input: 6.45 toks/s, output: 696.79 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 38/60 [10:25<05:55, 16.14s/it, est. speed input: 7.62 toks/s, output: 819.45 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 40/60 [10:31<04:03, 12.19s/it, est. speed input: 7.78 toks/s, output: 872.28 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 32/60 [10:35<10:33, 22.63s/it, est. speed input: 5.78 toks/s, output: 626.15 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 36/60 [10:39<05:01, 12.56s/it, est. speed input: 6.72 toks/s, output: 751.36 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 36/60 [10:41<07:26, 18.59s/it, est. speed input: 6.57 toks/s, output: 739.50 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 38/60 [10:49<05:10, 14.12s/it, est. speed input: 7.16 toks/s, output: 789.64 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 34/60 [11:22<09:53, 22.83s/it, est. speed input: 5.69 toks/s, output: 648.79 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 42/60 [11:48<06:01, 20.08s/it, est. speed input: 7.18 toks/s, output: 846.32 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 38/60 [12:04<07:52, 21.49s/it, est. speed input: 6.29 toks/s, output: 732.88 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 40/60 [12:07<05:11, 15.59s/it, est. speed input: 6.55 toks/s, output: 796.63 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 36/60 [12:07<09:06, 22.76s/it, est. speed input: 5.63 toks/s, output: 665.71 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 44/60 [12:24<05:11, 19.49s/it, est. speed input: 7.14 toks/s, output: 879.14 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 38/60 [12:28<06:59, 19.05s/it, est. speed input: 5.67 toks/s, output: 700.26 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 40/60 [12:34<04:45, 14.28s/it, est. speed input: 6.16 toks/s, output: 752.43 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 42/60 [12:36<04:32, 15.14s/it, est. speed input: 6.84 toks/s, output: 825.13 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 40/60 [12:34<08:33, 25.68s/it, est. speed input: 6.45 toks/s, output: 743.85 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 42/60 [12:37<03:06, 10.38s/it, est. speed input: 6.71 toks/s, output: 810.58 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 46/60 [12:51<04:08, 17.76s/it, est. speed input: 7.19 toks/s, output: 906.84 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 44/60 [12:58<02:46, 10.41s/it, est. speed input: 6.83 toks/s, output: 858.48 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 44/60 [13:03<03:54, 14.69s/it, est. speed input: 6.79 toks/s, output: 860.14 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 42/60 [13:05<06:47, 22.66s/it, est. speed input: 6.62 toks/s, output: 785.83 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 46/60 [13:34<02:57, 12.70s/it, est. speed input: 6.94 toks/s, output: 891.43 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/60 [14:10<04:50, 24.18s/it, est. speed input: 6.92 toks/s, output: 898.21 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 44/60 [14:16<07:03, 26.45s/it, est. speed input: 6.34 toks/s, output: 790.50 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 50/60 [14:27<03:15, 19.58s/it, est. speed input: 7.02 toks/s, output: 955.17 toks/s]Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 52/60 [14:27<01:49, 13.72s/it, est. speed input: 7.24 toks/s, output: 1030.34 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/60 [14:36<03:39, 18.28s/it, est. speed input: 6.71 toks/s, output: 895.62 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 46/60 [14:38<05:43, 24.51s/it, est. speed input: 6.44 toks/s, output: 833.37 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 50/60 [14:37<02:08, 12.85s/it, est. speed input: 6.94 toks/s, output: 969.76 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/60 [14:39<03:28, 17.34s/it, est. speed input: 6.69 toks/s, output: 898.79 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 50/60 [14:39<02:01, 12.18s/it, est. speed input: 6.92 toks/s, output: 972.78 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 46/60 [14:48<05:25, 23.28s/it, est. speed input: 6.40 toks/s, output: 824.72 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/60 [14:48<03:16, 16.38s/it, est. speed input: 6.63 toks/s, output: 895.96 toks/s]Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 52/60 [14:48<01:10,  8.83s/it, est. speed input: 7.07 toks/s, output: 1016.25 toks/s]Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 52/60 [15:00<01:10,  8.83s/it, est. speed input: 7.07 toks/s, output: 1016.25 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54/60 [15:30<01:18, 13.11s/it, est. speed input: 7.64 toks/s, output: 1017.72 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 54/60 [15:43<02:05, 20.95s/it, est. speed input: 6.83 toks/s, output: 1012.55 toks/s]Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/60 [16:16<01:01, 15.45s/it, est. speed input: 7.45 toks/s, output: 1037.66 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/60 [16:21<01:48, 18.15s/it, est. speed input: 6.57 toks/s, output: 986.33 toks/s]Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/60 [16:58<01:43, 25.87s/it, est. speed input: 6.51 toks/s, output: 994.83 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/60 [17:02<00:37, 18.74s/it, est. speed input: 7.30 toks/s, output: 1053.31 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [17:03<00:00, 13.26s/it, est. speed input: 7.53 toks/s, output: 1106.42 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [17:03<00:00, 13.26s/it, est. speed input: 7.53 toks/s, output: 1106.42 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [17:03<00:00, 17.06s/it, est. speed input: 7.53 toks/s, output: 1106.42 toks/s]
Overall avg Acc: 58.33%
ERROR 02-14 04:15:46 [core_client.py:564] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/60 [17:14<01:21, 20.31s/it, est. speed input: 6.47 toks/s, output: 987.44 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/60 [17:17<00:30, 15.17s/it, est. speed input: 6.63 toks/s, output: 1040.14 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/60 [17:19<02:30, 25.04s/it, est. speed input: 6.20 toks/s, output: 945.07 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/60 [17:25<00:41, 20.55s/it, est. speed input: 7.13 toks/s, output: 1029.77 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [17:48<00:00, 15.30s/it, est. speed input: 7.21 toks/s, output: 1070.28 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [17:48<00:00, 15.30s/it, est. speed input: 7.21 toks/s, output: 1070.28 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [17:48<00:00, 17.81s/it, est. speed input: 7.21 toks/s, output: 1070.28 toks/s]
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/60 [17:50<01:30, 22.66s/it, est. speed input: 6.19 toks/s, output: 971.92 toks/s]Overall avg Acc: 56.67%
ERROR 02-14 04:16:30 [core_client.py:564] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:07<00:00, 20.59s/it, est. speed input: 7.09 toks/s, output: 1043.73 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:07<00:00, 20.59s/it, est. speed input: 7.09 toks/s, output: 1043.73 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:07<00:00, 18.12s/it, est. speed input: 7.09 toks/s, output: 1043.73 toks/s]
Overall avg Acc: 60.0%
ERROR 02-14 04:16:48 [core_client.py:564] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.
Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/60 [18:22<00:41, 20.86s/it, est. speed input: 6.77 toks/s, output: 1002.82 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:32<00:00, 16.60s/it, est. speed input: 6.92 toks/s, output: 1051.40 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:32<00:00, 16.60s/it, est. speed input: 6.92 toks/s, output: 1051.40 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:32<00:00, 18.55s/it, est. speed input: 6.92 toks/s, output: 1051.40 toks/s]
Overall avg Acc: 56.67%
ERROR 02-14 04:17:12 [core_client.py:564] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.
Batch completed.
Starting task 5 with seed 24184 on GPU 0 (TP=1)
Starting task 6 with seed 14722 on GPU 1 (TP=1)
Starting task 7 with seed 1905 on GPU 2 (TP=1)
Starting task 8 with seed 222 on GPU 3 (TP=1)
INFO 02-14 04:17:21 [__init__.py:216] Automatically detected platform cuda.
INFO 02-14 04:17:21 [__init__.py:216] Automatically detected platform cuda.
INFO 02-14 04:17:21 [__init__.py:216] Automatically detected platform cuda.
INFO 02-14 04:17:21 [__init__.py:216] Automatically detected platform cuda.
AutoDeco model registered with transformers (AutoConfig, AutoModel, AutoModelForCausalLM)
AutoDeco model registered with transformers (AutoConfig, AutoModel, AutoModelForCausalLM)
AutoDeco model registered with transformers (AutoConfig, AutoModel, AutoModelForCausalLM)
AutoDeco model registered with transformers (AutoConfig, AutoModel, AutoModelForCausalLM)
INFO 02-14 04:17:26 [utils.py:328] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'model': 'ckpt/autodeco-qwen3-4b-thinking/'}
INFO 02-14 04:17:26 [utils.py:328] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'model': 'ckpt/autodeco-qwen3-4b-thinking/'}
INFO 02-14 04:17:26 [utils.py:328] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'model': 'ckpt/autodeco-qwen3-4b-thinking/'}
INFO 02-14 04:17:26 [utils.py:328] non-default args: {'max_model_len': 32768, 'disable_log_stats': True, 'model': 'ckpt/autodeco-qwen3-4b-thinking/'}
INFO 02-14 04:17:38 [__init__.py:742] Resolved architecture: AutoDecoModelForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 02-14 04:17:38 [__init__.py:1815] Using max model len 32768
INFO 02-14 04:17:38 [__init__.py:742] Resolved architecture: AutoDecoModelForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 02-14 04:17:38 [__init__.py:1815] Using max model len 32768
INFO 02-14 04:17:38 [__init__.py:742] Resolved architecture: AutoDecoModelForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 02-14 04:17:38 [__init__.py:1815] Using max model len 32768
INFO 02-14 04:17:38 [__init__.py:742] Resolved architecture: AutoDecoModelForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 02-14 04:17:38 [__init__.py:1815] Using max model len 32768
INFO 02-14 04:17:40 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-14 04:17:40 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-14 04:17:40 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 02-14 04:17:40 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=16384.
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:41 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:41 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:41 [core.py:76] Initializing a V1 LLM engine (v0.1.dev9404+gaad21055a) with config: model='ckpt/autodeco-qwen3-4b-thinking/', speculative_config=None, tokenizer='ckpt/autodeco-qwen3-4b-thinking/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=ckpt/autodeco-qwen3-4b-thinking/, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:41 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:41 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:41 [core.py:76] Initializing a V1 LLM engine (v0.1.dev9404+gaad21055a) with config: model='ckpt/autodeco-qwen3-4b-thinking/', speculative_config=None, tokenizer='ckpt/autodeco-qwen3-4b-thinking/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=ckpt/autodeco-qwen3-4b-thinking/, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:41 [core.py:76] Initializing a V1 LLM engine (v0.1.dev9404+gaad21055a) with config: model='ckpt/autodeco-qwen3-4b-thinking/', speculative_config=None, tokenizer='ckpt/autodeco-qwen3-4b-thinking/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=ckpt/autodeco-qwen3-4b-thinking/, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:41 [core.py:76] Initializing a V1 LLM engine (v0.1.dev9404+gaad21055a) with config: model='ckpt/autodeco-qwen3-4b-thinking/', speculative_config=None, tokenizer='ckpt/autodeco-qwen3-4b-thinking/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=ckpt/autodeco-qwen3-4b-thinking/, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[W214 04:17:44.471499049 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=7468)[0;0m WARNING 02-14 04:17:45 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[W214 04:17:45.518640742 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=7476)[0;0m WARNING 02-14 04:17:45 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[W214 04:17:45.546390835 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=7471)[0;0m WARNING 02-14 04:17:45 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [gpu_model_runner.py:2430] Starting to load model ckpt/autodeco-qwen3-4b-thinking/...
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [gpu_model_runner.py:2430] Starting to load model ckpt/autodeco-qwen3-4b-thinking/...
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [gpu_model_runner.py:2430] Starting to load model ckpt/autodeco-qwen3-4b-thinking/...
[W214 04:17:45.758884309 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:45 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=7477)[0;0m WARNING 02-14 04:17:45 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [gpu_model_runner.py:2462] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [autodeco.py:149] ================================================================================
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [autodeco.py:150] Initializing AutoDeco model for vLLM:
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [autodeco.py:151]   - base_model_type: qwen3
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [autodeco.py:152]   - use_enhanced_features: True
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [autodeco.py:153]   - hidden_size: 2560
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [autodeco.py:154] ================================================================================
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [autodeco.py:165]   - Loading base model class: Qwen3ForCausalLM
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:45 [gpu_model_runner.py:2430] Starting to load model ckpt/autodeco-qwen3-4b-thinking/...
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [gpu_model_runner.py:2462] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [autodeco.py:149] ================================================================================
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [autodeco.py:150] Initializing AutoDeco model for vLLM:
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [autodeco.py:151]   - base_model_type: qwen3
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [autodeco.py:152]   - use_enhanced_features: True
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [autodeco.py:153]   - hidden_size: 2560
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [autodeco.py:154] ================================================================================
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [autodeco.py:165]   - Loading base model class: Qwen3ForCausalLM
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [gpu_model_runner.py:2462] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [autodeco.py:149] ================================================================================
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [autodeco.py:150] Initializing AutoDeco model for vLLM:
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [autodeco.py:151]   - base_model_type: qwen3
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [autodeco.py:152]   - use_enhanced_features: True
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [autodeco.py:153]   - hidden_size: 2560
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [autodeco.py:154] ================================================================================
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [autodeco.py:165]   - Loading base model class: Qwen3ForCausalLM
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [cuda.py:362] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [cuda.py:362] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:45 [gpu_model_runner.py:2462] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:45 [autodeco.py:149] ================================================================================
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:45 [autodeco.py:150] Initializing AutoDeco model for vLLM:
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:45 [autodeco.py:151]   - base_model_type: qwen3
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:45 [autodeco.py:152]   - use_enhanced_features: True
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:45 [autodeco.py:153]   - hidden_size: 2560
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:45 [autodeco.py:154] ================================================================================
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:45 [autodeco.py:165]   - Loading base model class: Qwen3ForCausalLM
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [cuda.py:362] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [autodeco.py:201] âœ“ AutoDeco model initialized successfully
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [autodeco.py:202] ================================================================================
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:45 [autodeco.py:348] Loading AutoDeco weights from merged checkpoint...
[1;36m(EngineCore_DP0 pid=7468)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [autodeco.py:201] âœ“ AutoDeco model initialized successfully
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [autodeco.py:202] ================================================================================
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:45 [autodeco.py:348] Loading AutoDeco weights from merged checkpoint...
[1;36m(EngineCore_DP0 pid=7476)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:45 [cuda.py:362] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [autodeco.py:201] âœ“ AutoDeco model initialized successfully
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [autodeco.py:202] ================================================================================
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:45 [autodeco.py:348] Loading AutoDeco weights from merged checkpoint...
[1;36m(EngineCore_DP0 pid=7471)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:46 [autodeco.py:201] âœ“ AutoDeco model initialized successfully
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:46 [autodeco.py:202] ================================================================================
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:46 [autodeco.py:348] Loading AutoDeco weights from merged checkpoint...
[1;36m(EngineCore_DP0 pid=7477)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=7468)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:00<00:01,  1.47it/s]
[1;36m(EngineCore_DP0 pid=7476)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:00<00:01,  1.56it/s]
[1;36m(EngineCore_DP0 pid=7471)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:00<00:01,  1.56it/s]
[1;36m(EngineCore_DP0 pid=7477)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:00<00:01,  1.22it/s]
[1;36m(EngineCore_DP0 pid=7468)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:01<00:00,  1.29it/s]
[1;36m(EngineCore_DP0 pid=7471)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:01<00:00,  1.34it/s]
[1;36m(EngineCore_DP0 pid=7468)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  1.85it/s]
[1;36m(EngineCore_DP0 pid=7468)[0;0m 
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:47 [autodeco.py:359] âœ“ Successfully loaded 298 parameters
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:47 [autodeco.py:366]   - Base model (llm.*): 290 parameters
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:47 [autodeco.py:367]   - Temperature head (temp_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:47 [autodeco.py:368]   - Top-p head (top_p_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:47 [default_loader.py:268] Loading weights took 1.63 seconds
[1;36m(EngineCore_DP0 pid=7476)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:01<00:00,  1.22it/s]
[1;36m(EngineCore_DP0 pid=7471)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  1.93it/s]
[1;36m(EngineCore_DP0 pid=7471)[0;0m 
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:47 [autodeco.py:359] âœ“ Successfully loaded 298 parameters
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:47 [autodeco.py:366]   - Base model (llm.*): 290 parameters
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:47 [autodeco.py:367]   - Temperature head (temp_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:47 [autodeco.py:368]   - Top-p head (top_p_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:47 [default_loader.py:268] Loading weights took 1.56 seconds
[1;36m(EngineCore_DP0 pid=7476)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  2.03it/s]
[1;36m(EngineCore_DP0 pid=7476)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  1.78it/s]
[1;36m(EngineCore_DP0 pid=7476)[0;0m 
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:47 [autodeco.py:359] âœ“ Successfully loaded 298 parameters
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:47 [autodeco.py:366]   - Base model (llm.*): 290 parameters
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:47 [autodeco.py:367]   - Temperature head (temp_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:47 [autodeco.py:368]   - Top-p head (top_p_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:47 [default_loader.py:268] Loading weights took 1.69 seconds
[1;36m(EngineCore_DP0 pid=7477)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:01<00:00,  1.23it/s]
[1;36m(EngineCore_DP0 pid=7477)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  2.02it/s]
[1;36m(EngineCore_DP0 pid=7477)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:01<00:00,  1.72it/s]
[1;36m(EngineCore_DP0 pid=7477)[0;0m 
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:47 [autodeco.py:359] âœ“ Successfully loaded 298 parameters
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:47 [autodeco.py:366]   - Base model (llm.*): 290 parameters
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:47 [autodeco.py:367]   - Temperature head (temp_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:47 [autodeco.py:368]   - Top-p head (top_p_head.*): 4 parameters
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:47 [default_loader.py:268] Loading weights took 1.75 seconds
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:47 [gpu_model_runner.py:2484] Model loading took 7.6094 GiB and 2.021636 seconds
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:48 [gpu_model_runner.py:2484] Model loading took 7.6094 GiB and 2.059337 seconds
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:48 [gpu_model_runner.py:2484] Model loading took 7.6094 GiB and 2.088358 seconds
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:48 [gpu_model_runner.py:2484] Model loading took 7.6094 GiB and 1.935676 seconds
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:59 [backends.py:537] vLLM's torch.compile cache is disabled.
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:17:59 [backends.py:550] Dynamo bytecode transform time: 11.10 s
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:59 [backends.py:537] vLLM's torch.compile cache is disabled.
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:17:59 [backends.py:550] Dynamo bytecode transform time: 11.11 s
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:59 [backends.py:537] vLLM's torch.compile cache is disabled.
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:17:59 [backends.py:550] Dynamo bytecode transform time: 11.20 s
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:59 [backends.py:537] vLLM's torch.compile cache is disabled.
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:17:59 [backends.py:550] Dynamo bytecode transform time: 11.11 s
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:18:21 [backends.py:215] Compiling a graph for dynamic shape takes 19.57 s
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:18:21 [backends.py:215] Compiling a graph for dynamic shape takes 18.98 s
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:18:21 [backends.py:215] Compiling a graph for dynamic shape takes 19.41 s
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:18:21 [backends.py:215] Compiling a graph for dynamic shape takes 19.28 s
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:18:22 [monitor.py:34] torch.compile takes 30.66 s in total
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:18:22 [monitor.py:34] torch.compile takes 30.09 s in total
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:18:22 [monitor.py:34] torch.compile takes 30.52 s in total
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:18:22 [monitor.py:34] torch.compile takes 30.47 s in total
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:18:23 [gpu_worker.py:298] Available KV cache memory: 57.96 GiB
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:18:23 [gpu_worker.py:298] Available KV cache memory: 57.96 GiB
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:18:24 [gpu_worker.py:298] Available KV cache memory: 57.96 GiB
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:18:24 [gpu_worker.py:298] Available KV cache memory: 57.96 GiB
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:18:24 [kv_cache_utils.py:864] GPU KV cache size: 422,016 tokens
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:18:24 [kv_cache_utils.py:868] Maximum concurrency for 32,768 tokens per request: 12.88x
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:18:24 [kv_cache_utils.py:864] GPU KV cache size: 422,016 tokens
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:18:24 [kv_cache_utils.py:868] Maximum concurrency for 32,768 tokens per request: 12.88x
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:18:24 [kv_cache_utils.py:864] GPU KV cache size: 422,016 tokens
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:18:24 [kv_cache_utils.py:868] Maximum concurrency for 32,768 tokens per request: 12.88x
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:18:24 [kv_cache_utils.py:864] GPU KV cache size: 422,016 tokens
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:18:24 [kv_cache_utils.py:868] Maximum concurrency for 32,768 tokens per request: 12.88x
[1;36m(EngineCore_DP0 pid=7476)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|                                                     | 0/67 [00:00<?, ?it/s][1;36m(EngineCore_DP0 pid=7471)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|                                                     | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–ˆâ–Ž                                           | 2/67 [00:00<00:03, 18.89it/s][1;36m(EngineCore_DP0 pid=7468)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|                                                     | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–ˆâ–Ž                                           | 2/67 [00:00<00:03, 19.65it/s][1;36m(EngineCore_DP0 pid=7477)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|                                                     | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–ˆâ–ˆâ–ˆâ–Ž                                         | 5/67 [00:00<00:02, 21.03it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–ˆâ–Ž                                           | 2/67 [00:00<00:03, 18.61it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–ˆâ–Ž                                           | 2/67 [00:00<00:03, 18.30it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–ˆâ–ˆâ–ˆâ–Ž                                         | 5/67 [00:00<00:02, 21.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                       | 8/67 [00:00<00:02, 21.46it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–ˆâ–ˆâ–ˆâ–Ž                                         | 5/67 [00:00<00:03, 20.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–ˆâ–ˆâ–ˆâ–Ž                                         | 5/67 [00:00<00:03, 20.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                       | 8/67 [00:00<00:02, 21.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                                        | 7/67 [00:00<00:03, 19.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 11/67 [00:00<00:02, 19.61it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                       | 8/67 [00:00<00:03, 19.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 11/67 [00:00<00:02, 19.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 9/67 [00:00<00:03, 19.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                     | 10/67 [00:00<00:02, 19.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                  | 14/67 [00:00<00:02, 19.98it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 11/67 [00:00<00:02, 19.23it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                  | 14/67 [00:00<00:02, 18.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                    | 12/67 [00:00<00:03, 18.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                   | 13/67 [00:00<00:03, 17.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 17/67 [00:00<00:02, 19.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                  | 14/67 [00:00<00:02, 18.17it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 17/67 [00:00<00:02, 19.23it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                  | 15/67 [00:00<00:02, 18.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                 | 16/67 [00:00<00:02, 18.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 20/67 [00:01<00:02, 19.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 17/67 [00:00<00:02, 18.35it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 20/67 [00:01<00:02, 19.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                | 18/67 [00:00<00:02, 18.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                               | 19/67 [00:01<00:02, 18.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 23/67 [00:01<00:02, 19.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 23/67 [00:01<00:02, 19.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 20/67 [00:01<00:02, 18.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                           | 25/67 [00:01<00:02, 19.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 21/67 [00:01<00:02, 18.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                           | 25/67 [00:01<00:02, 19.91it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                             | 22/67 [00:01<00:02, 18.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 23/67 [00:01<00:02, 17.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 27/67 [00:01<00:02, 18.46it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                            | 24/67 [00:01<00:02, 18.18it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 27/67 [00:01<00:02, 18.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 29/67 [00:01<00:02, 15.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                           | 25/67 [00:01<00:02, 14.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 29/67 [00:01<00:02, 15.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 26/67 [00:01<00:02, 14.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 31/67 [00:01<00:02, 16.03it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 27/67 [00:01<00:02, 15.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 31/67 [00:01<00:02, 16.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 28/67 [00:01<00:02, 15.03it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 29/67 [00:01<00:02, 16.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 33/67 [00:01<00:02, 15.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 33/67 [00:01<00:02, 15.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 30/67 [00:01<00:02, 15.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 31/67 [00:01<00:02, 17.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 35/67 [00:01<00:01, 16.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 35/67 [00:01<00:01, 16.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 32/67 [00:01<00:02, 16.12it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 37/67 [00:02<00:01, 16.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 33/67 [00:01<00:02, 16.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 37/67 [00:02<00:01, 16.71it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 34/67 [00:02<00:02, 15.03it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 35/67 [00:02<00:01, 16.72it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 39/67 [00:02<00:01, 16.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 39/67 [00:02<00:01, 16.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 37/67 [00:02<00:01, 17.02it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 36/67 [00:02<00:01, 15.61it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 41/67 [00:02<00:01, 17.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 41/67 [00:02<00:01, 17.12it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 43/67 [00:02<00:01, 17.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 39/67 [00:02<00:01, 17.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 38/67 [00:02<00:01, 15.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 43/67 [00:02<00:01, 17.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 41/67 [00:02<00:01, 16.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 40/67 [00:02<00:01, 15.96it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 45/67 [00:02<00:01, 16.44it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 45/67 [00:02<00:01, 16.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 43/67 [00:02<00:01, 16.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 42/67 [00:02<00:01, 16.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 47/67 [00:02<00:01, 16.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 47/67 [00:02<00:01, 16.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 45/67 [00:02<00:01, 16.15it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 44/67 [00:02<00:01, 15.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 49/67 [00:02<00:01, 15.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 49/67 [00:02<00:01, 15.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 47/67 [00:02<00:01, 16.22it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 46/67 [00:02<00:01, 16.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 51/67 [00:02<00:00, 16.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 51/67 [00:02<00:01, 15.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 49/67 [00:02<00:01, 16.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 48/67 [00:02<00:01, 16.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 53/67 [00:03<00:00, 15.98it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 53/67 [00:03<00:00, 15.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 51/67 [00:02<00:00, 16.30it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 50/67 [00:02<00:01, 16.22it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 55/67 [00:03<00:00, 16.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 55/67 [00:03<00:00, 15.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 52/67 [00:03<00:00, 15.84it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 53/67 [00:03<00:00, 15.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 57/67 [00:03<00:00, 16.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 57/67 [00:03<00:00, 15.98it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/67 [00:03<00:00, 16.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 55/67 [00:03<00:00, 15.62it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 54/67 [00:03<00:00, 15.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/67 [00:03<00:00, 15.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/67 [00:03<00:00, 14.23it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 57/67 [00:03<00:00, 13.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 56/67 [00:03<00:00, 13.02it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/67 [00:03<00:00, 14.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 63/67 [00:03<00:00, 14.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/67 [00:03<00:00, 14.30it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 58/67 [00:03<00:00, 13.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 63/67 [00:03<00:00, 15.12it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65/67 [00:03<00:00, 15.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/67 [00:03<00:00, 14.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 60/67 [00:03<00:00, 14.20it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65/67 [00:03<00:00, 16.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:03<00:00, 15.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:03<00:00, 17.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 63/67 [00:03<00:00, 14.97it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 62/67 [00:03<00:00, 14.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:03<00:00, 16.11it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:03<00:00, 16.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65/67 [00:03<00:00, 15.46it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/67 [00:03<00:00, 15.00it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 15.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 16.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 66/67 [00:04<00:00, 15.53it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:04<00:00, 16.08it/s]
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:18:29 [gpu_model_runner.py:3215] Graph capturing finished in 5 secs, took 0.54 GiB
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:18:29 [gpu_worker.py:391] Free memory on device (78.57/79.18 GiB) on startup. Desired GPU memory utilization is (0.9, 71.26 GiB). Actual usage is 7.61 GiB for weight, 5.63 GiB for peak activation, 0.07 GiB for non-torch memory, and 0.54 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=61493640294` to fit into requested memory, or `--kv-cache-memory=69346530816` to fully utilize gpu memory. Current kv cache memory in use is 62229740646 bytes.
[1;36m(EngineCore_DP0 pid=7476)[0;0m INFO 02-14 04:18:29 [core.py:218] init engine (profile, create kv cache, warmup model) took 41.10 seconds
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:18:29 [gpu_model_runner.py:3215] Graph capturing finished in 5 secs, took 0.54 GiB
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:18:29 [gpu_worker.py:391] Free memory on device (78.57/79.18 GiB) on startup. Desired GPU memory utilization is (0.9, 71.26 GiB). Actual usage is 7.61 GiB for weight, 5.63 GiB for peak activation, 0.07 GiB for non-torch memory, and 0.54 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=61493640294` to fit into requested memory, or `--kv-cache-memory=69346465280` to fully utilize gpu memory. Current kv cache memory in use is 62229740646 bytes.
[1;36m(EngineCore_DP0 pid=7471)[0;0m INFO 02-14 04:18:29 [core.py:218] init engine (profile, create kv cache, warmup model) took 40.93 seconds
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:18:29 [gpu_model_runner.py:3215] Graph capturing finished in 5 secs, took 0.54 GiB
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:18:29 [gpu_worker.py:391] Free memory on device (78.57/79.18 GiB) on startup. Desired GPU memory utilization is (0.9, 71.26 GiB). Actual usage is 7.61 GiB for weight, 5.63 GiB for peak activation, 0.07 GiB for non-torch memory, and 0.54 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=61493640294` to fit into requested memory, or `--kv-cache-memory=69346465280` to fully utilize gpu memory. Current kv cache memory in use is 62229740646 bytes.
[1;36m(EngineCore_DP0 pid=7468)[0;0m INFO 02-14 04:18:29 [core.py:218] init engine (profile, create kv cache, warmup model) took 41.55 seconds
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:18:29 [gpu_model_runner.py:3215] Graph capturing finished in 5 secs, took 0.54 GiB
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:18:29 [gpu_worker.py:391] Free memory on device (78.57/79.18 GiB) on startup. Desired GPU memory utilization is (0.9, 71.26 GiB). Actual usage is 7.61 GiB for weight, 5.63 GiB for peak activation, 0.07 GiB for non-torch memory, and 0.54 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=61493640294` to fit into requested memory, or `--kv-cache-memory=69346530816` to fully utilize gpu memory. Current kv cache memory in use is 62229740646 bytes.
[1;36m(EngineCore_DP0 pid=7477)[0;0m INFO 02-14 04:18:29 [core.py:218] init engine (profile, create kv cache, warmup model) took 41.35 seconds
INFO 02-14 04:18:30 [llm.py:295] Supported_tasks: ['generate']
INFO 02-14 04:18:30 [__init__.py:36] No IOProcessor plugins requested by the model
INFO 02-14 04:18:30 [llm.py:295] Supported_tasks: ['generate']
INFO 02-14 04:18:30 [__init__.py:36] No IOProcessor plugins requested by the model
INFO 02-14 04:18:30 [llm.py:295] Supported_tasks: ['generate']
INFO 02-14 04:18:30 [__init__.py:36] No IOProcessor plugins requested by the model
INFO 02-14 04:18:30 [llm.py:295] Supported_tasks: ['generate']
INFO 02-14 04:18:30 [__init__.py:36] No IOProcessor plugins requested by the model
Adding requests:   0%|                                                                                             | 0/30 [00:00<?, ?it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 963.66it/s]
Processed prompts:   0%|                                       | 0/60 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Adding requests:   0%|                                                                                             | 0/30 [00:00<?, ?it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 749.28it/s]
Processed prompts:   0%|                                       | 0/60 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Adding requests:   0%|                                                                                             | 0/30 [00:00<?, ?it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 785.99it/s]
Processed prompts:   0%|                                       | 0/60 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Adding requests:   0%|                                                                                             | 0/30 [00:00<?, ?it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 831.13it/s]
Processed prompts:   0%|                                       | 0/60 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|â–‰                           | 2/60 [02:23<1:09:17, 71.67s/it, est. speed input: 2.15 toks/s, output: 96.22 toks/s]Processed prompts:   7%|â–ˆâ–‰                           | 4/60 [02:24<27:50, 29.82s/it, est. speed input: 4.15 toks/s, output: 191.46 toks/s]Processed prompts:   3%|â–‰                           | 2/60 [02:28<1:11:40, 74.14s/it, est. speed input: 2.23 toks/s, output: 95.77 toks/s]Processed prompts:   3%|â–‰                           | 2/60 [02:28<1:11:38, 74.11s/it, est. speed input: 2.08 toks/s, output: 96.66 toks/s]Processed prompts:   3%|â–‰                           | 2/60 [02:31<1:13:21, 75.88s/it, est. speed input: 2.03 toks/s, output: 91.59 toks/s]Processed prompts:   7%|â–ˆâ–‰                           | 4/60 [02:36<30:19, 32.49s/it, est. speed input: 3.85 toks/s, output: 179.07 toks/s]Processed prompts:   7%|â–ˆâ–‰                           | 4/60 [02:35<30:29, 32.68s/it, est. speed input: 3.86 toks/s, output: 183.10 toks/s]Processed prompts:   7%|â–ˆâ–‰                           | 4/60 [02:38<31:20, 33.58s/it, est. speed input: 3.92 toks/s, output: 177.03 toks/s]Processed prompts:  10%|â–ˆâ–ˆâ–‰                          | 6/60 [02:42<17:09, 19.06s/it, est. speed input: 5.74 toks/s, output: 263.13 toks/s]Processed prompts:  10%|â–ˆâ–ˆâ–‰                          | 6/60 [02:42<18:12, 20.24s/it, est. speed input: 5.74 toks/s, output: 265.86 toks/s]Processed prompts:  13%|â–ˆâ–ˆâ–ˆâ–Š                         | 8/60 [02:59<13:34, 15.66s/it, est. speed input: 5.98 toks/s, output: 331.05 toks/s]Processed prompts:  10%|â–ˆâ–ˆâ–‰                          | 6/60 [03:10<23:03, 25.62s/it, est. speed input: 4.87 toks/s, output: 234.03 toks/s]Processed prompts:  10%|â–ˆâ–ˆâ–‰                          | 6/60 [03:18<24:53, 27.65s/it, est. speed input: 4.68 toks/s, output: 222.03 toks/s]Processed prompts:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 10/60 [03:25<12:18, 14.77s/it, est. speed input: 6.50 toks/s, output: 377.24 toks/s]Processed prompts:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 12/60 [03:32<08:45, 10.94s/it, est. speed input: 6.94 toks/s, output: 451.58 toks/s]Processed prompts:  13%|â–ˆâ–ˆâ–ˆâ–Š                         | 8/60 [03:33<16:58, 19.58s/it, est. speed input: 5.02 toks/s, output: 285.62 toks/s]Processed prompts:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 10/60 [03:37<11:07, 13.35s/it, est. speed input: 5.55 toks/s, output: 367.22 toks/s]Processed prompts:  13%|â–ˆâ–ˆâ–ˆâ–Š                         | 8/60 [03:42<20:19, 23.45s/it, est. speed input: 4.80 toks/s, output: 278.47 toks/s]Processed prompts:  13%|â–ˆâ–ˆâ–ˆâ–Š                         | 8/60 [03:42<18:53, 21.80s/it, est. speed input: 4.79 toks/s, output: 279.80 toks/s]Processed prompts:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 10/60 [03:58<14:56, 17.94s/it, est. speed input: 5.59 toks/s, output: 340.28 toks/s]Processed prompts:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 12/60 [04:04<10:11, 12.74s/it, est. speed input: 6.08 toks/s, output: 413.85 toks/s]Processed prompts:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 10/60 [04:19<17:03, 20.48s/it, est. speed input: 4.67 toks/s, output: 314.28 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 14/60 [04:20<08:37, 11.26s/it, est. speed input: 6.24 toks/s, output: 469.33 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 14/60 [04:24<12:06, 15.80s/it, est. speed input: 6.15 toks/s, output: 444.01 toks/s]Processed prompts:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 12/60 [04:26<11:46, 14.73s/it, est. speed input: 5.54 toks/s, output: 379.20 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 16/60 [04:49<10:52, 14.83s/it, est. speed input: 6.71 toks/s, output: 482.57 toks/s]Processed prompts:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 12/60 [04:51<17:06, 21.38s/it, est. speed input: 5.06 toks/s, output: 343.84 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 14/60 [04:58<11:52, 15.49s/it, est. speed input: 5.45 toks/s, output: 410.37 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 14/60 [05:01<11:59, 15.64s/it, est. speed input: 5.40 toks/s, output: 412.21 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 16/60 [05:16<09:47, 13.34s/it, est. speed input: 5.90 toks/s, output: 467.71 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 16/60 [05:19<09:59, 13.62s/it, est. speed input: 5.83 toks/s, output: 466.76 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 18/60 [05:29<07:52, 11.25s/it, est. speed input: 6.71 toks/s, output: 519.50 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 18/60 [05:37<12:19, 17.61s/it, est. speed input: 6.79 toks/s, output: 492.18 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 18/60 [05:44<09:13, 13.17s/it, est. speed input: 6.42 toks/s, output: 512.33 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 20/60 [05:46<06:19,  9.48s/it, est. speed input: 6.93 toks/s, output: 586.30 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 22/60 [05:55<05:02,  7.96s/it, est. speed input: 7.66 toks/s, output: 635.64 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 20/60 [05:57<10:12, 15.30s/it, est. speed input: 7.08 toks/s, output: 542.92 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 22/60 [05:59<06:55, 10.93s/it, est. speed input: 7.57 toks/s, output: 616.22 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 24/60 [06:11<05:37,  9.39s/it, est. speed input: 7.78 toks/s, output: 653.54 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 20/60 [06:27<11:12, 16.80s/it, est. speed input: 6.12 toks/s, output: 519.35 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 16/60 [06:32<20:59, 28.62s/it, est. speed input: 4.75 toks/s, output: 384.67 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 18/60 [06:58<16:37, 23.74s/it, est. speed input: 5.29 toks/s, output: 432.42 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 22/60 [07:03<10:51, 17.15s/it, est. speed input: 6.09 toks/s, output: 551.20 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 20/60 [07:10<12:15, 18.39s/it, est. speed input: 5.50 toks/s, output: 494.54 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 26/60 [07:16<09:17, 16.40s/it, est. speed input: 6.99 toks/s, output: 626.73 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 24/60 [07:28<11:46, 19.63s/it, est. speed input: 6.44 toks/s, output: 575.32 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 26/60 [07:52<09:51, 17.39s/it, est. speed input: 6.42 toks/s, output: 619.00 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 22/60 [08:15<14:17, 22.57s/it, est. speed input: 5.09 toks/s, output: 502.59 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 24/60 [08:26<14:44, 24.58s/it, est. speed input: 5.39 toks/s, output: 535.72 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 28/60 [08:49<11:01, 20.67s/it, est. speed input: 6.04 toks/s, output: 590.47 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 28/60 [08:52<13:49, 25.91s/it, est. speed input: 6.01 toks/s, output: 579.09 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 30/60 [09:10<08:47, 17.58s/it, est. speed input: 6.20 toks/s, output: 640.57 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 30/60 [09:25<11:33, 23.11s/it, est. speed input: 6.03 toks/s, output: 603.63 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 24/60 [09:30<16:16, 27.12s/it, est. speed input: 4.76 toks/s, output: 483.84 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 32/60 [09:30<07:54, 16.96s/it, est. speed input: 6.27 toks/s, output: 668.07 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 26/60 [09:34<11:05, 19.58s/it, est. speed input: 5.28 toks/s, output: 521.47 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 28/60 [09:39<07:42, 14.46s/it, est. speed input: 5.59 toks/s, output: 579.71 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 34/60 [10:04<07:20, 16.95s/it, est. speed input: 6.34 toks/s, output: 703.44 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 36/60 [10:10<05:03, 12.66s/it, est. speed input: 6.61 toks/s, output: 760.10 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 26/60 [10:10<18:35, 32.79s/it, est. speed input: 4.82 toks/s, output: 515.00 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 30/60 [10:14<07:41, 15.38s/it, est. speed input: 5.54 toks/s, output: 577.29 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 28/60 [10:21<13:04, 24.51s/it, est. speed input: 5.02 toks/s, output: 577.47 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 38/60 [10:25<04:07, 11.25s/it, est. speed input: 7.14 toks/s, output: 810.66 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 30/60 [11:03<11:45, 23.51s/it, est. speed input: 4.99 toks/s, output: 588.34 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 32/60 [11:07<08:44, 18.74s/it, est. speed input: 5.75 toks/s, output: 589.94 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 32/60 [11:13<14:22, 30.80s/it, est. speed input: 5.38 toks/s, output: 585.50 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 32/60 [11:20<08:51, 18.97s/it, est. speed input: 5.11 toks/s, output: 603.52 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 34/60 [11:25<10:08, 23.39s/it, est. speed input: 5.66 toks/s, output: 641.25 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 34/60 [11:25<06:06, 14.08s/it, est. speed input: 5.53 toks/s, output: 636.92 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 36/60 [12:22<09:58, 24.95s/it, est. speed input: 5.54 toks/s, output: 656.69 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 34/60 [12:24<10:41, 24.66s/it, est. speed input: 5.39 toks/s, output: 598.48 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 36/60 [12:27<07:38, 19.10s/it, est. speed input: 5.66 toks/s, output: 646.50 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 36/60 [12:33<07:25, 18.56s/it, est. speed input: 5.67 toks/s, output: 655.35 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 38/60 [12:42<07:31, 20.51s/it, est. speed input: 5.96 toks/s, output: 704.99 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 40/60 [12:52<05:14, 15.73s/it, est. speed input: 6.15 toks/s, output: 755.29 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 40/60 [12:52<09:56, 29.82s/it, est. speed input: 6.09 toks/s, output: 719.81 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 42/60 [13:01<03:44, 12.45s/it, est. speed input: 6.58 toks/s, output: 803.25 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 38/60 [13:09<07:14, 19.77s/it, est. speed input: 5.68 toks/s, output: 676.23 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 38/60 [13:10<06:47, 18.52s/it, est. speed input: 5.70 toks/s, output: 695.57 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 42/60 [13:15<07:19, 24.44s/it, est. speed input: 6.20 toks/s, output: 768.37 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 44/60 [13:16<02:55, 10.94s/it, est. speed input: 6.68 toks/s, output: 849.00 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 40/60 [13:22<04:56, 14.83s/it, est. speed input: 5.90 toks/s, output: 755.58 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 40/60 [13:24<05:21, 16.08s/it, est. speed input: 5.87 toks/s, output: 731.98 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 42/60 [13:28<03:31, 11.74s/it, est. speed input: 6.09 toks/s, output: 794.37 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 42/60 [13:31<03:31, 11.73s/it, est. speed input: 6.10 toks/s, output: 810.02 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 44/60 [14:01<03:23, 12.69s/it, est. speed input: 6.36 toks/s, output: 836.66 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 46/60 [14:10<02:22, 10.21s/it, est. speed input: 6.69 toks/s, output: 894.65 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 44/60 [14:11<03:56, 14.79s/it, est. speed input: 6.17 toks/s, output: 822.94 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/60 [14:13<01:31,  7.60s/it, est. speed input: 6.89 toks/s, output: 951.80 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 44/60 [14:14<06:54, 25.89s/it, est. speed input: 6.17 toks/s, output: 782.18 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 46/60 [14:40<04:44, 20.30s/it, est. speed input: 6.30 toks/s, output: 829.51 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 46/60 [14:48<03:42, 15.87s/it, est. speed input: 6.36 toks/s, output: 854.10 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 46/60 [14:51<05:31, 23.69s/it, est. speed input: 6.15 toks/s, output: 811.75 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 50/60 [14:51<01:50, 11.05s/it, est. speed input: 6.83 toks/s, output: 984.26 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/60 [14:51<03:19, 16.60s/it, est. speed input: 6.38 toks/s, output: 884.90 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 50/60 [14:51<01:56, 11.64s/it, est. speed input: 6.60 toks/s, output: 958.05 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/60 [14:54<02:24, 12.02s/it, est. speed input: 6.58 toks/s, output: 914.63 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 50/60 [14:55<01:24,  8.46s/it, est. speed input: 6.80 toks/s, output: 987.33 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/60 [14:56<03:18, 16.52s/it, est. speed input: 6.56 toks/s, output: 887.96 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 50/60 [14:57<01:57, 11.78s/it, est. speed input: 6.78 toks/s, output: 959.30 toks/s]Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 52/60 [15:16<01:35, 11.91s/it, est. speed input: 6.85 toks/s, output: 993.12 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/60 [16:25<01:51, 18.59s/it, est. speed input: 6.54 toks/s, output: 988.25 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/60 [16:55<01:59, 19.94s/it, est. speed input: 6.35 toks/s, output: 972.20 toks/s]Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/60 [18:00<01:32, 23.04s/it, est. speed input: 6.14 toks/s, output: 974.36 toks/s]Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/60 [18:02<01:50, 27.56s/it, est. speed input: 6.72 toks/s, output: 956.64 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/60 [18:03<00:34, 17.40s/it, est. speed input: 6.89 toks/s, output: 1026.98 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/60 [18:03<00:39, 19.54s/it, est. speed input: 6.88 toks/s, output: 1015.50 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/60 [18:18<02:48, 28.09s/it, est. speed input: 5.87 toks/s, output: 916.61 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/60 [18:20<03:00, 30.01s/it, est. speed input: 5.86 toks/s, output: 916.57 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:25<00:00, 16.87s/it, est. speed input: 6.97 toks/s, output: 1045.96 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:25<00:00, 16.87s/it, est. speed input: 6.97 toks/s, output: 1045.96 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:25<00:00, 18.42s/it, est. speed input: 6.97 toks/s, output: 1045.96 toks/s]
Overall avg Acc: 55.0%
ERROR 02-14 04:36:57 [core_client.py:564] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:54<00:00, 19.68s/it, est. speed input: 6.79 toks/s, output: 1030.83 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:54<00:00, 19.68s/it, est. speed input: 6.79 toks/s, output: 1030.83 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [18:54<00:00, 18.92s/it, est. speed input: 6.79 toks/s, output: 1030.83 toks/s]
Overall avg Acc: 53.33%
ERROR 02-14 04:37:27 [core_client.py:564] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.
Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/60 [19:12<01:55, 28.99s/it, est. speed input: 5.81 toks/s, output: 924.10 toks/s]Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/60 [19:14<01:51, 27.96s/it, est. speed input: 5.75 toks/s, output: 926.68 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/60 [19:21<00:43, 21.60s/it, est. speed input: 6.42 toks/s, output: 974.64 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/60 [19:29<00:47, 23.65s/it, est. speed input: 5.88 toks/s, output: 965.99 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [19:29<00:00, 16.76s/it, est. speed input: 6.59 toks/s, output: 1016.48 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [19:29<00:00, 16.76s/it, est. speed input: 6.59 toks/s, output: 1016.48 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [19:29<00:00, 19.48s/it, est. speed input: 6.59 toks/s, output: 1016.48 toks/s]
Overall avg Acc: 58.33%
ERROR 02-14 04:38:01 [core_client.py:564] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [19:42<00:00, 19.02s/it, est. speed input: 6.51 toks/s, output: 1009.90 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [19:42<00:00, 19.02s/it, est. speed input: 6.51 toks/s, output: 1009.90 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [19:42<00:00, 19.71s/it, est. speed input: 6.51 toks/s, output: 1009.90 toks/s]
Overall avg Acc: 56.67%
ERROR 02-14 04:38:14 [core_client.py:564] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.
Batch completed.
All tasks completed.
